{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4cf4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import time\n",
    "import urllib\n",
    "import csv  \n",
    "import json  \n",
    "import requests\n",
    "from csv import writer\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download webdriver from  then unzip and place in existing directory. \n",
    "\n",
    "# Credit: reference code MP 2.1 Year 2021 from the teaching team of CS 410 \n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Chrome('./chromedriver',options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6496285",
   "metadata": {},
   "source": [
    "This link has all doctors' name at Cook County Healty at Illinois - https://cookcountyhealth.org/about/physicians-directory/ . There are 823 doctors in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uses webdriver object to execute javascript code and get dynamically loaded webcontent\n",
    "def get_js_soup(url,driver):\n",
    "    driver.get(url)\n",
    "    res_html = driver.execute_script('return document.body.innerHTML')\n",
    "    soup = BeautifulSoup(res_html,'html.parser') #beautiful soup object to be used for parsing html content\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ded2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts all Faculty Profile page urls from the Directory Listing Page\n",
    "def scrape_dir_page(dir_url,driver):\n",
    "    print ('-'*20,'Scraping directory page','-'*20)\n",
    "    faculty_links = []\n",
    "    faculty_base_url = 'https://cookcountyhealth.org/about/physicians-directory/'\n",
    "    #execute js on webpage to load faculty listings on webpage and get ready to parse the loaded HTML \n",
    "    soup = get_js_soup(dir_url,driver)  \n",
    "    for link_holder in soup.find_all('h1',class_='elementor-post__title'): #get list of all of class 'name'\n",
    "        rel_link = link_holder.find('a')['href'] #get url\n",
    "        #rel_link = rel_link.rsplit('/', 1)[-1]\n",
    "        print(rel_link)\n",
    "        #url returned is relative, so we need to add base url\n",
    "        faculty_links.append(rel_link) \n",
    "    print ('-'*20,'Found {} faculty profile urls'.format(len(faculty_links)),'-'*20)\n",
    "    return faculty_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652442d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_url = 'https://cookcountyhealth.org/about/physicians-directory/' #url of directory listings of CS faculty\n",
    "list_url = []\n",
    "faculty_links = []\n",
    "for i in range(1, 34): \n",
    "     url = dir_url + str(i) + '/'\n",
    "     list_url.append(url)\n",
    "for j in list_url: \n",
    "    fac = scrape_dir_page(j,driver)\n",
    "    faculty_links.append(fac)\n",
    "faculty_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of physicians in Cook County Health\n",
    "\n",
    "fac_links = []\n",
    "for sublist in faculty_links:\n",
    "    for num in sublist:\n",
    "        fac_links.append(num)\n",
    "\n",
    "len(fac_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235511aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in fac_links: \n",
    "    \n",
    "    # multiple sessions tries to avoid http connections errors https://stackoverflow.com/questions/23013220/max-retries-exceeded-with-url-in-requests/47475019#47475019\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "\n",
    "    \n",
    "    page = session.get(url)\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all('div', class_='blog-post blog-post-wrapper physicians')\n",
    "    print(results)\n",
    "\n",
    "    with open('doctors.csv', 'a', newline='', encoding='utf8') as f:\n",
    "        thewriter = writer(f)\n",
    "        #header = ['Name', 'Specialty', 'Location', 'Education', 'Residency', 'Board Certification']\n",
    "        #thewriter.writerow(header)\n",
    "    \n",
    "        for result in results: \n",
    "            out = result.find('img')['alt']\n",
    "            name = out.rsplit(', ', 1)[0]\n",
    "            print(name)\n",
    "            try: \n",
    "                specialty = result.find(text='Specialty:').findNext('h6').text\n",
    "                specialty = \"\".join(specialty.rstrip())\n",
    "                print(specialty)\n",
    "            except AttributeError:\n",
    "                specialty = \"nil\"\n",
    "                print(specialty)   \n",
    "            try: \n",
    "                location = result.find(text='Location(s):').findNext('h6').text\n",
    "                location = \"\".join(location.rstrip())\n",
    "                location =  re.sub(r\"^\\W+|\\W+$\", \"\", location) #regex reference https://stackoverflow.com/questions/22650506/how-to-rermove-non-alphanumeric-characters-at-the-beginning-or-end-of-a-string\n",
    "                print(location)\n",
    "            except AttributeError:\n",
    "                location = \"nil\"\n",
    "                print(location)    \n",
    "            try: \n",
    "                education = result.find(text='Medical Education: ').findNext('h6').text\n",
    "                education = \"\".join(education.rstrip())\n",
    "                print(education)\n",
    "            except AttributeError:\n",
    "                education = \"nil\"\n",
    "                print(education)\n",
    "            try: \n",
    "                residency = result.find(text='Residency: ').findNext('h6').text\n",
    "                residency = \"\".join(residency.rstrip())\n",
    "                print(residency)\n",
    "            except AttributeError:\n",
    "                residency = \"nil\"\n",
    "                print(residency)\n",
    "            try: \n",
    "                certification = result.find(text='Board Certification: ').findNext('h6').text\n",
    "                certification = \"\".join(certification.rstrip())\n",
    "                print(certification)\n",
    "            except AttributeError:\n",
    "                certification = \"nil\"\n",
    "                print(certification)\n",
    "            doctorinfo = [name, specialty, location, education, residency, certification]\n",
    "            thewriter.writerow(doctorinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff4ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CSV to Json Converter Code taken from https://www.codespeedy.com/converting-csv-to-json-array-in-python/\n",
    "\n",
    "def csv_to_json(csvFile, jsonFile):    \n",
    "    jsondict = {}  \n",
    "    with open(csvFile) as csvfile:  \n",
    "        csv_data = csv.DictReader(csvfile)#Converting the csv data into dictionary\n",
    "        jsondict[\"data\"]=[]\n",
    "        for rows in csv_data:  \n",
    "            print(rows)#Just for reference\n",
    "            jsondict[\"data\"].append(rows)  #Appending all the csv rows\n",
    "  \n",
    "    with open(jsonFile, 'w', encoding='utf8') as jsonfile:  \n",
    "        #Dumping the data into jsonfile.json\n",
    "        jsonfile.write(json.dumps(jsondict, indent = 4))  #indent is used for pretty printing \n",
    "csvfile = 'doctors-latest.csv'  \n",
    "jsonfile = 'doctors-test.json'  \n",
    "  \n",
    "csv_to_json(csvfile, jsonfile)#Calling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('doctors-test.json') as f:\n",
    "    json_dict = json.load(f)\n",
    "json_dict\n",
    "\n",
    "## Function to remove empty keys taken from https://gist.github.com/nlohmann/c899442d8126917946580e7f84bf7ee7\n",
    "\n",
    "def remove_empty_elements(d):\n",
    "    \"\"\"recursively remove empty lists, empty dicts, or None elements from a dictionary\"\"\"\n",
    "\n",
    "    def empty(x):\n",
    "        return x is None or x == {} or x == [] or x == \"nil\"\n",
    "\n",
    "    if not isinstance(d, (dict, list)):\n",
    "        return d\n",
    "    elif isinstance(d, list):\n",
    "        return [v for v in (remove_empty_elements(v) for v in d) if not empty(v)]\n",
    "    else:\n",
    "        return {k: v for k, v in ((k, remove_empty_elements(v)) for k, v in d.items()) if not empty(v)}\n",
    "#remove_empty_elements(json_dict)\n",
    "\n",
    "import json\n",
    "with open('doctors-remove-nil.json', 'w') as fp:\n",
    "    json.dump(remove_empty_elements(json_dict), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889ae83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
